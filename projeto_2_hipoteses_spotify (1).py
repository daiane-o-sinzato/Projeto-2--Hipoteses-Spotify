# -*- coding: utf-8 -*-
"""Projeto 2- Hipoteses Spotify

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oXf6l8IvsLpRr9vtab8ENiX-iMWSwhM-

Contexto:

Projeto 2- Hipoteses Spotify

**Passo 1: **Conectar as tabelas ao ambiente de consulta e visualizar os dados
"""

!pip install pandas
import pandas as pd

# Carregar as três tabelas:
df1_Competition = pd.read_csv('/content/track_in_competition - competition.csv')
df2_Spotify = pd.read_csv('/content/track_in_spotify - spotify.csv')
df3_Technical = pd.read_csv('/content/track_technical_info - technical_info.csv')

# Visualizar as primeiras 5 linhas de df1
print(df1_Competition.info())

# Visualizar as primeiras 5 linhas de df2
print(df2_Spotify.info())

# Visualizar as primeiras 5 linhas de df3
print(df3_Technical.info())

"""Montar ambiente de junção das tabelas"""

# Mesclar todos de uma vez
Projeto2_clean = pd.merge(pd.merge(df1_Competition, df2_Spotify, on='track_id'), df3_Technical, on='track_id')
print(Projeto2_clean.info(5))  # Visualize o DataFrame final

"""Eliminar dados de Shazam"""

# Remover coluna shazam por ter nulos e estar foro de escopo
Projeto2_clean = Projeto2_clean.drop(['in_shazam_charts'], axis=1)#da tabela junta

# Verificar se as colunas foi eliminada com sucesso
print(Projeto2_clean.info())#tabela pronta

"""Remover nulos"""

# Remover linhas com valores não numéricos na coluna streams
Projeto2_clean = Projeto2_clean[pd.to_numeric(Projeto2_clean['streams'], errors='coerce').notnull()]#da tabela pronta

# Converter a coluna streams para int64
Projeto2_clean['streams'] = Projeto2_clean['streams'].astype(int)

# Converter a coluna deezer playlists para int64
Projeto2_clean['in_deezer_playlists'] = Projeto2_clean['in_deezer_playlists'].str.replace(',', '').astype(int)

# Verificar se as colunas foi convertida com sucesso
print(Projeto2_clean.info())#tabela pronta

"""Utilizar as colunas de ano, mês e dia para formar a data de lançamento"""

# Criar a coluna 'data_de_lancamento' em df
def combine_date(row):
    year = row['released_year']
    month = row['released_month']
    day = row['released_day']
    try:
        return pd.Timestamp(year=year, month=month, day=day)
    except (ValueError, TypeError):
        return pd.NaT

Projeto2_clean['data_de_lancamento'] = Projeto2_clean.apply(combine_date, axis=1)
print(Projeto2_clean.info)

"""Teste Shapiro-Wilk: . Um valor-p menor que um determinado nível de significância (geralmente 0.05) sugere que os dados não vêm de uma distribuição normal.


"""

from scipy.stats import shapiro # Importar o teste de Shapiro-Wilk

# Teste de normalidade para a coluna 'bpm' em df3
stat, p_value = shapiro(df3_Technical['bpm'])
print("Teste de Shapiro-Wilk para BPM:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'streams' em df2
stat, p_value = shapiro(Projeto2_clean['streams'])
print("Teste de Shapiro-Wilk para Streams:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'spotify_playlists' em df1
stat, p_value = shapiro(df2_Spotify['in_spotify_playlists'])
print("Teste de Shapiro-Wilk para Spotify_Playlists:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'deezer_playlists' em df1
stat, p_value = shapiro(Projeto2_clean['in_deezer_playlists'])
print("Teste de Shapiro-Wilk para Deezer_Playlists:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'apple_playlists' em df1
stat, p_value = shapiro(df1_Competition['in_apple_playlists'])
print("Teste de Shapiro-Wilk para Apple_Playlists:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'spotify_charts' em df2
stat, p_value = shapiro(df2_Spotify['in_spotify_charts'])
print("Teste de Shapiro-Wilk para Spotify_Charts:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'deezer_charts' em df1
stat, p_value = shapiro(df1_Competition['in_deezer_charts'])
print("Teste de Shapiro-Wilk para Deezer_Charts:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'apple_charts' em df1
stat, p_value = shapiro(df1_Competition['in_apple_charts'])
print("Teste de Shapiro-Wilk para Apple_Charts:")
print("Estatística de teste:", stat)
print("P-value:", p_value)


# Teste de normalidade para a coluna 'dançabilidade' em df3
stat, p_value = shapiro(df3_Technical['danceability_%'])
print("Teste de Shapiro-Wilk para Dançabilidade:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'valence' em df3
stat, p_value = shapiro(df3_Technical['valence_%'])
print("Teste de Shapiro-Wilk para Valencia:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'energy' em df3
stat, p_value = shapiro(df3_Technical['energy_%'])
print("Teste de Shapiro-Wilk para Energia:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'acousticness' em df3
stat, p_value = shapiro(df3_Technical['acousticness_%'])
print("Teste de Shapiro-Wilk para Acústico:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'liveness' em df3
stat, p_value = shapiro(df3_Technical['liveness_%'])
print("Teste de Shapiro-Wilk para Ao vivo:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

# Teste de normalidade para a coluna 'speechiness' em df3
stat, p_value = shapiro(df3_Technical['liveness_%'])
print("Teste de Shapiro-Wilk para Linhas Vocais:")
print("Estatística de teste:", stat)
print("P-value:", p_value)

#Variavéis avaliadas e resultados do teste para novas colunas
data = {'Variavél':['BPM','Streams', 'Spotify_Playlists', 'Deezer_Playlists', 'Apple_Playlists','Spotify_Charts', 'Deezer_Charts', 'Apple_Charts','Dançabilidade' , 'Valencia', 'Energia', 'Acústico', 'Ao vivo','Linhas vocais'],
'Estatística de Teste': [0.9775400161743164,  0.7614117860794067, 0.6233949661254883, 0.3616788983345032,0.7208691239356995,  0.6656914949417114, 0.5037872195243835, 0.8839874863624573,  0.9797065258026123, 0.9775001406669617, 0.9806259870529175, 0.8713008761405945, 0.7714425325393677, 0.7714425325393677],
'P-Value':[5.849364048682304e-11, 5.759937816269185e-35, 2.585255536832855e-41, 0.0, 4.262229766486136e-37, 1.3128821364197784e-39, 1.401298464324817e-45, 4.256710084607299e-26, 2.961017542268962e-10, 5.6825145283712075e-11,  6.088498039069634e-10, 2.7208141955093187e-27, 2.05334664435416e-34, 2.05334664435416e-34]}


# Criar DataFrame
df = pd.DataFrame(data)

# Mostrar tabela
print(df)

"""Calcular a soma de Playlists e Charts"""

# Verificar se as colunas existem nos DataFrames e calcular a soma
if 'in_apple_playlists' in df1_Competition.columns and 'in_deezer_playlists' in df1_Competition.columns and 'in_spotify_playlists' in df2_Spotify.columns:
    # Converter todas as células das colunas para strings e substituir vírgulas por vazio
    apple_playlists = Projeto2_clean['in_apple_playlists'].astype(str).str.replace(',', '').fillna('0')
    deezer_playlists = Projeto2_clean['in_deezer_playlists'].astype(str).str.replace(',', '').fillna('0')
    spotify_playlists = Projeto2_clean['in_spotify_playlists'].astype(str).str.replace(',', '').fillna('0')

    'streams' in df2_Spotify.columns and 'streams' in df2_Spotify.columns
    # Converter todas as células das colunas para strings e substituir vírgulas por vazio
    streams =Projeto2_clean['streams'].astype(str).str.replace(',', '').fillna('0')

    # Converter as strings resultantes em inteiros
    apple_playlists = apple_playlists.astype(int)
    deezer_playlists = deezer_playlists.astype(int)
    spotify_playlists = spotify_playlists.astype(int)

    # Calcular a soma das playlists
    Projeto2_clean['soma_playlists'] = apple_playlists + deezer_playlists + spotify_playlists

    # Print DataFrame information after removing null values
print(Projeto2_clean.info())

"""**Hipótese 1: Músicas com BPM mais altos fazem mais sucesso em termos de número de streams no Spotify: REFUTADO"""

from scipy.stats import mannwhitneyu

# Filtrar os dados para incluir apenas os streams do Spotify
spotify_streams = Projeto2_clean['in_spotify_playlists']

# Definir os limites dos quartis para 'streams' no Spotify
low_streams_spotify = spotify_streams.quantile(0.25)
high_streams_spotify = spotify_streams.quantile(0.75)

# Dividir os dados em dois grupos com base nos limites dos quartis de 'streams' no Spotify
low_streams_group = Projeto2_clean[spotify_streams <= low_streams_spotify]['bpm']
high_streams_group = Projeto2_clean[spotify_streams > high_streams_spotify]['bpm']

# Aplicar o teste de Mann-Whitney U entre os dois grupos
statistic, p_value = mannwhitneyu(low_streams_group, high_streams_group)

# Imprimir os resultados do teste
print("Estatística do teste:", statistic)
print("Valor p:", p_value)

"""Hipótese 2 - Músicas mais populares no ranking do Spotify também possuem um comportamento semelhante em outras plataformas, como a Deezer e Apple:

1.   Spotify e Deezer: Refutado
2.   Spoify e Apple: Confirmado


"""

from scipy.stats import mannwhitneyu

# Filtrar os dados para incluir apenas os streams do Spotify, Deezer e Apple Music
spotify_streams = Projeto2_clean['in_spotify_charts']
deezer_streams = Projeto2_clean['in_deezer_charts']
apple_streams = Projeto2_clean['in_apple_charts']

# Comparação entre o número de streams no Spotify e no Deezer
spotify_streams = Projeto2_clean.loc[Projeto2_clean['in_spotify_charts'] == 1, 'streams']  # 1 indica que está no chart
deezer_streams = Projeto2_clean.loc[Projeto2_clean['in_deezer_charts'] == 1, 'streams']
apple_streams = Projeto2_clean.loc[Projeto2_clean['in_apple_charts'] == 1, 'streams']

# Realizar o teste de Mann-Whitney U
statistic_spotify_deezer, p_value_spotify_deezer = mannwhitneyu(spotify_streams, deezer_streams, alternative='two-sided')
print("Hipótese 2 - Comparação entre Spotify e Deezer:")
print("Mann-Whitney U statistic:", statistic_spotify_deezer)
print("P-value:", p_value_spotify_deezer)

statistic_spotify_apple, p_value_spotify_apple = mannwhitneyu(spotify_streams, apple_streams, alternative='two-sided')
print("Hipótese 2 - Comparação entre Spotify e Apple:")
print("Mann-Whitney U statistic:", statistic_spotify_apple)
print("P-value:", p_value_spotify_apple)

# Contar o número de músicas de cada artista no Spotify, Deezer e Apple Music
spotify_artist_track_count = Projeto2_clean[df2_Spotify.notnull()].groupby('artist(s)_name').size()
deezer_artist_track_count = Projeto2_clean[df2_Spotify.notnull()].groupby('artist(s)_name').size()
apple_artist_track_count = Projeto2_clean[df2_Spotify.notnull()].groupby('artist(s)_name').size()

# Definir os limites dos quartis para o número de músicas por artista no Spotify
poucas_musicas_spotify = spotify_artist_track_count.quantile(0.25)
muitas_musicas_spotify = spotify_artist_track_count.quantile(0.75)

# Separar os artistas em dois grupos com base no número de músicas que possuem no Spotify
poucas_musicas_artistas_spotify = spotify_artist_track_count[spotify_artist_track_count <= poucas_musicas_spotify].index
muitas_musicas_artistas_spotify = spotify_artist_track_count[spotify_artist_track_count > muitas_musicas_spotify].index

# Separar os dados em dois grupos com base no número de músicas dos artistas no Spotify
poucas_musicas_streams_spotify = Projeto2_clean[Projeto2_clean['artist(s)_name'].isin(poucas_musicas_artistas_spotify) & spotify_streams.notnull()]['streams']
muitas_musicas_streams_spotify = Projeto2_clean[Projeto2_clean['artist(s)_name'].isin(muitas_musicas_artistas_spotify) & spotify_streams.notnull()]['streams']

"""Hipótese 3 - A presença de uma música em um maior número de playlists está correlacionada com um maior número de streams: CONFIRMADO"""

from scipy.stats import spearmanr

# Calcular a correlação de Spearman entre o total de playlists e o número de streams
correlation, p_value = spearmanr(Projeto2_clean['soma_playlists'], Projeto2_clean['streams'])

# Imprimir os resultados do teste
print("Hipótese 3 - Correlação entre o total de playlists e o número de streams:", correlation)
print("Valor p:", p_value)

"""Hipótese 4 - Artistas com um maior número de músicas no Spotify têm mais streams: CONFIRMADO"""

from scipy.stats import mannwhitneyu

# Calcular o número de músicas de cada artista
artist_tracks = Projeto2_clean.groupby('artist(s)_name')['track_id'].count()

# Definir um limiar para o número de músicas que um artista deve ter para ser considerado "muitas músicas"
threshold = 10
muitas_faixas = artist_tracks[artist_tracks >= threshold].index # Muitas faixas
poucas_faixas = artist_tracks[artist_tracks < threshold].index # Poucas faixas

# Filtrar o DataFrame com base nos índices muitas_faixas e poucas_faixas
muitas_faixas_data = Projeto2_clean[Projeto2_clean['artist(s)_name'].isin(muitas_faixas)]
poucas_faixas_data = Projeto2_clean[Projeto2_clean['artist(s)_name'].isin(poucas_faixas)]

# Comparação entre artistas com muitas músicas e artistas com poucas músicas
muitas_faixas_streams = muitas_faixas_data['streams']
poucas_faixas_streams = poucas_faixas_data['streams']

# Realizar o teste de Mann-Whitney U
statistic, p_value = mannwhitneyu(muitas_faixas_streams, poucas_faixas_streams, alternative='two-sided')
print("Hipótese 4 - Comparação entre artistas com muitas músicas e artistas com poucas músicas:")
print("Mann-Whitney U statistic:", statistic)
print("P-value:", p_value)

"""Hipótese 5 - As características da música influenciam o sucesso em termos de número de streams no Spotify:

Lista

*   Dançabilidade: Confirmado
*   Valencia: Refutada
*   Energia: Refutada
*   Acustico: Refutada
*   Instrumental: Refutada
*   Ao vivo: Confirmado
*   Linhas vocais: Confirmado

"""

from scipy.stats import mannwhitneyu

# Filtrar os dados para incluir apenas os streams do Spotify
spotify_streams = Projeto2_clean['in_spotify_playlists'] > 0

# Definir os limites dos quartis para 'danceability'
baixa_dancabilidade = Projeto2_clean[spotify_streams]['danceability_%'].quantile(0.25)
alta_dancabilidade = Projeto2_clean[spotify_streams]['danceability_%'].quantile(0.75)

# Separar os dados em dois grupos com base no quartil de 'danceability'
baixa_dancabilidade = Projeto2_clean[(Projeto2_clean['danceability_%'] <= baixa_dancabilidade) & spotify_streams]['streams']
alta_dancabilidade = Projeto2_clean[(Projeto2_clean['danceability_%'] > alta_dancabilidade) & spotify_streams]['streams']

# Aplicar o teste de Mann-Whitney U
u_stat, p_value = mannwhitneyu(baixa_dancabilidade, alta_dancabilidade)
print("Hipótese 5 - Influência da dancabilidade no número de streams:")
print("U-statistic:", u_stat)
print("P-value:", p_value)

# Definir os limites dos quartis para 'valence'
baixa_valencia = Projeto2_clean[spotify_streams]['valence_%'].quantile(0.25)
alta_valencia = Projeto2_clean[spotify_streams]['valence_%'].quantile(0.75)

# Separar os dados em dois grupos com base no quartil de 'valence'
baixa_valencia = Projeto2_clean[(Projeto2_clean['valence_%'] <= baixa_valencia) & spotify_streams]['streams']
alta_valencia = Projeto2_clean[(Projeto2_clean['valence_%'] > alta_valencia) & spotify_streams]['streams']

# Aplicar o teste de Mann-Whitney U
u_stat, p_value = mannwhitneyu(baixa_valencia, alta_valencia)
print("Hipótese 5 - Influência de valence no número de streams:")
print("U-statistic:", u_stat)
print("P-value:", p_value)

# Definir os limites dos quartis para 'energia'
baixa_energia = Projeto2_clean[spotify_streams]['energy_%'].quantile(0.25)
alta_energia = Projeto2_clean[spotify_streams]['energy_%'].quantile(0.75)

# Separar os dados em dois grupos com base no quartil de 'energia'
baixa_energia = Projeto2_clean[(Projeto2_clean['energy_%'] <= baixa_energia) & spotify_streams]['streams']
alta_energia = Projeto2_clean[(Projeto2_clean['energy_%'] > alta_energia) & spotify_streams]['streams']

# Aplicar o teste de Mann-Whitney U
u_stat, p_value = mannwhitneyu(baixa_energia, alta_energia)
print("Hipótese 5 - Influência da energia no número de streams:")
print("U-statistic:", u_stat)
print("P-value:", p_value)

# Definir os limites dos quartis para 'acustico'
pouco_acustico = Projeto2_clean[spotify_streams]['acousticness_%'].quantile(0.25)
muito_acustico = Projeto2_clean[spotify_streams]['acousticness_%'].quantile(0.75)

# Separar os dados em dois grupos com base no quartil de 'energia'
pouco_acustico = Projeto2_clean[(Projeto2_clean['acousticness_%'] <= pouco_acustico) & spotify_streams]['streams']
muito_acustico = Projeto2_clean[(Projeto2_clean['acousticness_%'] > muito_acustico) & spotify_streams]['streams']

# Aplicar o teste de Mann-Whitney U
u_stat, p_value = mannwhitneyu(pouco_acustico, muito_acustico)
print("Hipótese 5 - Influência do acustico no número de streams:")
print("U-statistic:", u_stat)
print("P-value:", p_value)

# Definir os limites dos quartis para 'instrumental'
pouco_instrumental = Projeto2_clean[spotify_streams]['instrumentalness_%'].quantile(0.25)
muito_instrumental= Projeto2_clean[spotify_streams]['instrumentalness_%'].quantile(0.75)

# Separar os dados em dois grupos com base no quartil de 'instrumental'
pouco_instrumental = Projeto2_clean[(Projeto2_clean['instrumentalness_%'] <= pouco_instrumental) & spotify_streams]['streams']
muito_instrumental = Projeto2_clean[(Projeto2_clean['instrumentalness_%'] > muito_instrumental) & spotify_streams]['streams']

# Aplicar o teste de Mann-Whitney U
u_stat, p_value = mannwhitneyu(pouco_instrumental, muito_instrumental)
print("Hipótese 5 - Influência do instrumental no número de streams:")
print("U-statistic:", u_stat)
print("P-value:", p_value)

# Definir os limites dos quartis para 'live'
pouco_aovivo = Projeto2_clean[spotify_streams]['liveness_%'].quantile(0.25)
muito_aovivo = Projeto2_clean[spotify_streams]['liveness_%'].quantile(0.75)

# Separar os dados em dois grupos com base no quartil de 'ao vivo'
pouco_aovivo = Projeto2_clean[(Projeto2_clean['liveness_%'] <= pouco_aovivo) & spotify_streams]['streams']
muito_aovivo = Projeto2_clean[(Projeto2_clean['liveness_%'] > muito_aovivo) & spotify_streams]['streams']

# Aplicar o teste de Mann-Whitney U
u_stat, p_value = mannwhitneyu(pouco_aovivo, muito_aovivo)
print("Hipótese 5 - Influência do ao vivo no número de streams:")
print("U-statistic:", u_stat)
print("P-value:", p_value)

# Definir os limites dos quartis para 'linhas vocais'
baixa_linhasvocais = Projeto2_clean[spotify_streams]['speechiness_%'].quantile(0.25)
alta_linhasvocais = Projeto2_clean[spotify_streams]['speechiness_%'].quantile(0.75)

# Separar os dados em dois grupos com base no quartil de 'linhas vocais'
baixa_linhasvocais = Projeto2_clean[(Projeto2_clean['speechiness_%'] <= baixa_linhasvocais) & spotify_streams]['streams']
alta_linhasvocais = Projeto2_clean[(Projeto2_clean['speechiness_%'] > alta_linhasvocais) & spotify_streams]['streams']

# Aplicar o teste de Mann-Whitney U
u_stat, p_value = mannwhitneyu(baixa_linhasvocais, alta_linhasvocais)
print("Hipótese 5 - Influência do linhas vocais no número de streams:")
print("U-statistic:", u_stat)
print("P-value:", p_value)

import numpy as np
import matplotlib.pyplot as plt

# Dados das variáveis e seus valores
variaveis = ['Dançabilidade', 'Valencia', 'Energia', 'Acústico', 'Instrumental', 'Linhas vocais', 'Ao vivo', ]

estatisticas_teste = [31923, 29182, 28694, 33007, 37092, 44058, 40162]

p_values = [0.019, 0.4121, 0.3594, 0.1107, 0.9101, 0.002, 0.051 ]

# Criando o gráfico de radar
fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(polar=True))

# Ajustando os ângulos das variáveis
theta = np.linspace(0, 2 * np.pi, len(variaveis), endpoint=False).tolist()

# Adicionando as variáveis e seus valores ao gráfico
ax.plot(theta, estatisticas_teste, color='r', linestyle='solid', linewidth=2, label='Estatística de Teste')
ax.fill(theta, estatisticas_teste, color='r', alpha=0.25)
ax.plot(theta, p_values, color='b', linestyle='solid', linewidth=2, label='P-Value')
ax.fill(theta, p_values, color='b', alpha=0.25)

# Adicionando rótulos de variáveis
ax.set_xticks(theta)
ax.set_xticklabels(variaveis)

# Adicionando legenda
ax.legend(loc='upper right')

# Mostrando o gráfico
plt.show()

"""Regressão Linear"""

#importa o modelo
import statsmodels.api as sm

# Hipótese 1 - Músicas com BPM mais altos fazem mais sucesso
X = Projeto2_clean['bpm']
Y = Projeto2_clean['in_spotify_playlists']
X = sm.add_constant(X)  # Adiciona uma constante para o termo independente
model = sm.OLS(Y, X).fit()
print("Hipótese 1 - Músicas com BPM mais altos fazem mais sucesso:")
print(model.summary())

# Hipótese 2 - Comparação entre Spotify e Deezer
X = Projeto2_clean['in_deezer_charts']
Y = Projeto2_clean['in_spotify_charts']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 2 - Comparação entre Spotify e Deezer:")
print(model.summary())

# Hipótese 2 - Comparação entre Spotify e Apple
X = Projeto2_clean['in_apple_charts']
Y = Projeto2_clean['in_spotify_charts']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 2 - Comparação entre Spotify e Apple:")
print(model.summary())

# Hipótese 3 - Correlação entre playlists e streams
X = Projeto2_clean['soma_playlists']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 3 - Correlação entre playlists e streams:")
print(model.summary())

# Hipótese 4 - Artistas com um maior número de músicas têm mais streams
X = Projeto2_clean['artist_count']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 4 - Artistas com um maior número de músicas têm mais streams:")
print(model.summary())

# Hipótese 5 - Influência da danceability no número de streams
X = Projeto2_clean['danceability_%']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 5 - Influência da danceability no número de streams:")
print(model.summary())

# Hipótese 5 - Influência da energy no número de streams
X = Projeto2_clean['energy_%']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 5 - Influência da energy no número de streams:")
print(model.summary())

# Hipótese 5 - Influência da valence no número de streams
X = Projeto2_clean['valence_%']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 5 - Influência da valence no número de streams:")
print(model.summary())

# Hipótese 5 - Influência da liveness no número de streams
X = Projeto2_clean['liveness_%']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 5 - Influência da liveness no número de streams:")
print(model.summary())

# Hipótese 5 - Influência da instrumentalness no número de streams
X = Projeto2_clean['instrumentalness_%']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 5 - Influência da instrumentalness no número de streams:")
print(model.summary())

# Hipótese 5 - Influência da acousticness no número de streams
X = Projeto2_clean['acousticness_%']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 5 - Influência da acousticness no número de streams:")
print(model.summary())

# Hipótese 5 - Influência da speechiness no número de streams
X = Projeto2_clean['speechiness_%']
Y = Projeto2_clean['streams']
X = sm.add_constant(X)
model = sm.OLS(Y, X).fit()
print("\nHipótese 5 - Influência da speechiness no número de streams:")
print(model.summary())

import matplotlib.pyplot as plt
import numpy as np

# Dados das hipóteses
hipoteses = [
    "Músicas com BPM mais altos fazem mais sucesso",
    "Comparação entre Spotify e Deezer",
    "Comparação entre Spotify e Apple",
    "Correlação entre playlists e streams",
    "Artistas com um maior número de músicas têm mais sucesso"
]
r_squared = [0.000, 0.343, 0.346, 0.586, 0.008]
f_statistic = [0.01101, 382.0, 388.3, 1039.0, 5.878]
p_values = [9.16e-01, 8.67e-69, 1.1e-69, 1.24e-142, 1.56e-02]

# Tamanho dos pontos com base nos p-values
sizes = [2000 * (-np.log10(p)) for p in p_values]

# Criando o gráfico de dispersão
plt.figure(figsize=(10, 6))
plt.scatter(r_squared, f_statistic, s=sizes, alpha=0.5)

# Adicionando rótulos aos pontos
for i, txt in enumerate(hipoteses):
    plt.annotate(txt, (r_squared[i], f_statistic[i]), fontsize=8)

# Adicionando rótulos e título
plt.xlabel("R-squared")
plt.ylabel("F-statistic")
plt.title("Relação entre R-squared, F-statistic e P-value das Hipóteses")

# Exibindo o gráfico
plt.grid(True)
plt.show()

!pip install tabulate #instalar o pacote

from tabulate import tabulate #importar tabela do pacote tabela

# Hipótese 1
hipotese1 = [
    ["Estatística", "Valor"],
    ["Teste", "Mann-Whitney U"],
    ["U-statistic", 28736.0],
    ["P-value", 0.7828]
]
print("Hipótese 1 - Músicas com BPM mais altos fazem mais sucesso:")
print(tabulate(hipotese1, headers="firstrow"))

# Hipótese 2
hipotese2_deezer = [
    ["Estatística", "Valor"],
    ["Teste", "Mann-Whitney U"],
    ["U-statistic", 1017.0],
    ["P-value", 0.639]
]
print("\nHipótese 2 - Comparação entre Spotify e Deezer:")
print(tabulate(hipotese2_deezer, headers="firstrow"))

# Hipótese 2
hipotese2_apple = [
    ["Estatística", "Valor"],
    ["Teste", "Mann-Whitney U"],
    ["U-statistic", 438.0],
    ["P-value", 0.033]
]
print("\nHipótese 2 - Comparação entre Spotify e Apple:")
print(tabulate(hipotese2_apple, headers="firstrow"))

# Hipótese 3
hipotese3 = [
    ["Estatística", "Valor"],
    ["Correlação",  0.8326],
    ["P-value", 5.030]
]
print("\nHipótese 3 - Correlação entre playlists e streams:")
print(tabulate(hipotese3, headers="firstrow"))

# Hipótese 4
hipotese4 = [
    ["Estatística", "Valor"],
    ["Teste", "Mann-Whitney U"],
    ["U-statistic", 47506],
    ["P-value", 0.013]
]
print("\nHipótese 4 - Artistas com um maior número de músicas têm mais streams:")
print(tabulate(hipotese4, headers="firstrow"))

# Hipótese 5
hipotese5 = [
    ["Característica", "U-statistic", "P-value"],
    ["Danceability", 31923.0, 0.019],
    ["Energy", 28694, 0.3594],
    ["Valence", 29182.5, 0.4121],
    ["Liveness", 40162, 0.051],
    ["Instrumentalness", 37092, 0.910],
    ["Acousticness", 33007, 0.1107],
    ["Speechiness", 44058, 0.002]
]
print("\nHipótese 5 - Influência das características da música no número de streams:")
print(tabulate(hipotese5, headers="firstrow"))

"""Histograma"""

import matplotlib.pyplot as plt
import seaborn as sns

# Filtrar por data
filtered_data = Projeto2_clean[Projeto2_clean['data_de_lancamento'] >= '2020-01-01']

# Histograma para data_lancamento
plt.figure(figsize=(10, 6))
sns.histplot(filtered_data['data_de_lancamento'], bins=10)  # Use filtered data for 2020+ dates
plt.title('Histograma de Data de Lançamento')
plt.xlabel('Data de Lançamento')
plt.ylabel('Frequência')
plt.xticks(rotation=45)

# Histograma para total_playlists
plt.figure(figsize=(10, 6))
sns.histplot(Projeto2_clean['soma_playlists'], bins=10)
plt.title('Histograma de Total de Playlists')
plt.xlabel('Total de Playlists')
plt.ylabel('Frequência')
plt.show()

"""Resultado das Hipoteses"""

from tabulate import tabulate

# Dados dos resultados das hipóteses
results = {
    "Hipótese": ["Músicas com BPM mais altos fazem mais sucesso",
                 "Comparação entre Spotify e Deezer",
                 "Comparação entre Spotify e Apple",
                 "Correlação entre playlists e streams",
                 "Artistas com um maior número de músicas têm mais streams",
                 "Influência da danceability no número de streams",
                 "Influência da energy no número de streams",
                 "Influência da valence no número de streams",
                 "Influência da liveness no número de streams",
                 "Influência da instrumentalness no número de streams",
                 "Influência da acousticness no número de streams",
                 "Influência da speechiness no número de streams"],
    "R-squared": [0.000, 0.360, 0.305, 0.613, 0.019, 0.011, 0.001, 0.002, 0.002, 0.002, 0.000, 0.013],
    "Adj. R-squared": [-0.001, 0.359, 0.304, 0.613, 0.018, 0.010, -0.001, 0.001, 0.001, 0.001, -0.001, 0.012],
    "F-statistic": [0.3703, 534.7, 416.3, 1506, 18.03, 10.68, 0.6452, 1.586, 2.225, 1.919, 0.019, 12.14],
    "Prob (F-statistic)": [0.543, 3.39e-94, 5.07e-77, 3.99e-198, 239e-05, 0.001, 0.422, 0.208, 0.136, 0.166, 0.890, 0.005]
}

"""Visualizar as hipoteses em gráfico"""

import matplotlib.pyplot as plt

# Dados dos resultados das hipóteses
results = {
    'Variáveis': ['BPM', 'Deezer', 'Apple', 'Playlists vs Streams', 'Músicas vs Streams',
                  'Dançabilidade', 'Valencia', 'Energia', 'Acústico', 'Instrumental',
                  'Linhas vocais', 'Ao vivo'],
    'Estatística de Teste': [28736, 1017, 4380, 0.8326, 47560, 31923, 29182, 28694,
                              33007, 37092, 44058, 40162],
    'P-Value': [0.7828, 0.639, 0.033, 5.03, 0.013, 0.019, 0.4121, 0.3594,
                0.1107, 0.9101, 0.002, 0.051]
}

# Criar DataFrame
df = pd.DataFrame(results)

# Definir tamanho da figura
plt.figure(figsize=(12, 8))

# Plotar gráfico de barras para Estatística de Teste
plt.subplot(2, 1, 1)
plt.bar(df['Variáveis'], df['Estatística de Teste'], color='blue')
plt.title('Estatística de Teste')
plt.xlabel('Variáveis')
plt.ylabel('Valor')

# Plotar gráfico de dispersão para P-Value
plt.subplot(2, 1, 2)
plt.scatter(df['Variáveis'], df['P-Value'], color='red')
plt.title('P-Value')
plt.xlabel('Variáveis')
plt.ylabel('Valor')

# Ajustar layout
plt.tight_layout()

# Mostrar o gráfico
plt.show()

import pandas as pd
from tabulate import tabulate

# Dados dos resultados das hipóteses
results = {
    'Variáveis': ['BPM', 'Deezer', 'Apple', 'Playlists vs Streams', 'Músicas vs Streams',
                  'Dançabilidade', 'Valencia', 'Energia', 'Acústico', 'Instrumental',
                  'Linhas vocais', 'Ao vivo'],
    'Estatística de Teste': [28736, 1017.0, 4380, 0.8326, 47560, 31923,
                             29182, 28694, 33007, 37092, 44058, 40162],
    'P-Value': [0.7828, 0.639, 0.033, 5.030, 0.013, 0.019, 0.4121, 0.3594,
                0.1107, 0.9101, 0.002, 0.051]
}

# Criar DataFrame
df = pd.DataFrame(results)

# Exibir a tabela
print(tabulate(df, headers='keys', tablefmt='fancy_grid'))

"""revisoes"""

# Verificar se há valores não numéricos em todas as colunas
for column in Projeto2_clean.columns:
    if Projeto2_clean[column].dtype == 'object':
        non_numeric_values = Projeto2_clean[column].loc[Projeto2_clean[column].str.contains('[^0-9.]', na=False)]
        if not non_numeric_values.empty:
            print(f"Valores não numéricos encontrados na coluna {column}:")
            print(non_numeric_values)

# Supondo que 'danceability_%' seja a coluna em que você deseja substituir os valores nulos
Projeto2_clean['danceability_%'] = df3_Technical['danceability_%'].fillna("Não informado")

# Criar colunas de perfil com base nas características musicais
Projeto2_clean['dançabilidade'] = pd.cut(df3_Technical['danceability_%'], bins=[float('-inf'), 24, 48, 71, 95, float('inf')], labels=['Não informado', 'Pouco Dançante', 'Dançante moderado', 'Dançante', 'Muito Dançante'])

# Criar colunas de perfil com base nas características musicais
Projeto2_clean['acústico'] = pd.cut(df3_Technical['acousticness_%'], bins=[float('-inf'), 8, 18, 43, 97, float('inf')], labels=['Não informado', 'Pouco Acústico', 'Acústico Moderado', 'Acústico', 'Muito Acústico'])

# Criar colunas de perfil com base nas características musicais
Projeto2_clean['ao vivo'] = pd.cut(df3_Technical['liveness_%'], bins=[float('-inf'), 10, 12, 24, 97, float('inf')], labels=['Não informado', 'Não é ao vivo', 'Ao vivo moderado', 'Parcialmente ao vivo', 'Ao vivo'])

# Criar colunas de perfil com base nas características musicais
Projeto2_clean['linhas vocais'] = pd.cut(df3_Technical['speechiness_%'], bins=[float('-inf'), 4, 6, 11, 64, float('inf')], labels=['Não informado', 'Pouco vocal', 'Vocal moderado', 'Vocal', 'Muito vocal'])


# Supondo que 'valence_%' seja a coluna em que você deseja substituir os valores nulos
Projeto2_clean['energia'] = df3_Technical['valence_%'].fillna("Não informado")
# Criar coluna 'positividade_perfil' com base nas características musicais
Projeto2_clean['positividade_perfil'] = pd.cut(df3_Technical['valence_%'], bins=[float('-inf'), 22, 51, 70, 97, float('inf')], labels=['Não informado','low energy', 'meddium energy', 'high energy','eletrizant energy'])

# Criar coluna de Score Segmentado
Projeto2_clean['score_segmentado'] = df3_Technical[['danceability_%', 'energy_%', 'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%', 'valence_%']].sum(axis=1)
#Adicionar coluna 'harmonia'
Projeto2_clean['harmonia'] = df3_Technical['key'].map({'A': 'Lá', 'A#': 'Lá Sustenido', 'B': 'Si', 'B#': 'Si Sustenido', 'C': 'Dó', 'C#': 'Dó Sustenido', 'D': 'Ré', 'D#': 'Ré Sustenido', 'E': 'Mi', 'E#':'Mi Sustenido','F': 'Fá', 'F#':'Fá Sustenido', 'G': 'Sol','G#': 'Sol Sustenido', 'b': 'Bemol'})
Projeto2_clean['modo_escala'] = df3_Technical['mode'].map({'Minor': 'Escala dramática', 'Major': 'Escala heróica'}).fillna('Indefinido')

Projeto2_clean['perfil_ouvintes'] = pd.cut(Projeto2_clean['score_segmentado'], bins=4, labels=['Low Profile', 'Medium Profile', 'High Profile', 'Eletrizante Profile'])
print(df.head())

# Create a new column 'bpm_categoria' based on 'bpm' values
Projeto2_clean['bpm_categoria'] = pd.cut(df3_Technical['bpm'], bins=[0, 90, 120, 160, 180], labels=['Lento', 'Moderado', 'Rápido', 'Muito rápido'])
print(Projeto2_clean.info)
print(model.summary())

"""Random Forest"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from datetime import datetime, timedelta

# Converta a coluna de data para o formato DateTime, se necessário
Projeto2_clean['data_de_lancamento'] = pd.to_datetime(Projeto2_clean['data_de_lancamento'])

# Obtenha a data atual
data_atual = datetime.now()

# Calcule a data de início há 2 anos atrás
data_inicio = data_atual - timedelta(days=2*365)  # 2 anos = 2 * 365 dias

# Filtre o DataFrame para incluir apenas observações dos últimos 2 anos
filtered_data = Projeto2_clean[Projeto2_clean['data_de_lancamento'] >= data_inicio]

# Separar os dados em características (X) e variável alvo (y)
X = Projeto2_clean[['valence_%', 'energy_%', 'danceability_%', 'acousticness_%', 'liveness_%']]
y = Projeto2_clean['streams']

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar o modelo Gradient Boosting
model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Treinar o modelo
model.fit(X_train, y_train)

# Fazer previsões
predictions = model.predict(X_test)

# Avaliar o modelo
mae = mean_absolute_error(y_test, predictions)
mse = mean_squared_error(y_test, predictions)
rmse = mean_squared_error(y_test, predictions, squared=False)
r2 = r2_score(y_test, predictions)

print("Mean Absolute Error:", mae)
print("Mean Squared Error:", mse)
print("Root Mean Squared Error:", rmse)
print("R-squared:", r2)

import matplotlib.pyplot as plt

# Dados
hipoteses = ['BPM', 'Deezer', 'Apple', 'Playlists vs Streams', 'Músicas vs Streams',
             'Dançabilidade', 'Valência', 'Energia', 'Acústico', 'Instrumental',
             'Linhas vocais', 'Ao vivo']
resultado = ['Refutada', 'Refutada', 'Confirmada', 'Confirmada', 'Confirmada',
             'Confirmada', 'Refutada', 'Refutada', 'Refutada', 'Refutada',
             'Confirmada', 'Confirmada']

# Plot
plt.figure(figsize=(10, 6))
colors = ['red' if res == 'Refutada' else 'gray' for res in resultado]
plt.barh(hipoteses, [1] * len(hipoteses), color=colors)
plt.xlabel('Resultado')
plt.title('Hipóteses Refutadas vs Confirmadas')
plt.xlim(0, 1.2)
plt.gca().invert_yaxis()
plt.show()

"""Transformar em CSV e extrair"""

import pandas as pd

# Exportar Projeto2_clean para um arquivo CSV
Projeto2_clean.to_csv('consultas_projeto2_clean.csv', index=False)
print(Projeto2_clean.info())

